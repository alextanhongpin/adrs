# LLM


## Status

`draft`


## Context

We want to design the architecture for LLM. First, we need to identify the common stages when developing LLM architecture:

- loading: data source (converted into Documents(text, type, metadata))
- indexing: creating vector embeddings + metadatas
- storing: vector database
- querying: transform query into embeddings, building relevant metadata and call the vector store
- evaluation: how effective is the strategy?

Each step can be an interface:

```go
type Loader interface {
  Load(ctx context.Context) ([]byte, error)
}

type Indexer interface {
	Index(ctx context.Context, data []byte) error
}

// The rest...
```


This abstractions can later be used to build even higher level of abstractions, such as query engine, chat engine and agents.
